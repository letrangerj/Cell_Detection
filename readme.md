# 4I Pipeline

This project implements a pipeline for analyzing multi-round fluorescence imaging data using YOLO and SAM (Segment Anything Model) for cell detection and segmentation.

(note that this readme.md is generated by AI, basing on the codes)

## Table of Contents

1. [Overview](#overview)
2. [File Structure](#file-structure)
3. [Installation](#installation)
4. [Usage](#usage)
5. [Scripts](#scripts)
6. [Output](#output)

## Overview

The 4I Pipeline is designed to process multi-round fluorescence imaging data, detect cells, and analyze their intensities across different imaging rounds. It uses a combination of YOLO (You Only Look Once) for initial cell detection and SAM (Segment Anything Model) for precise cell segmentation.

## File Structure

### Before Image Alignment

The initial file structure, before running the image alignment script, should be as follows:

```
Origin_path/
├── frame_1/
│   ├── R1/
│   │   ├── 1.png (channel-merged image)
│   │   ├── xxxch0.png (single channel image)
│   │   └── ...
│   ├── R2/
│   ├── R3/
│   └── ...
├── frame_2/
├── frame_3/
└── ...

# ImageJ alignment file for each frame
Origin_path/
├── frame_1/
│   └── TileConfiguration.registered.txt
├── frame_2/
│   └── TileConfiguration.registered.txt
└── ...
```

### After Image Alignment

After running the image alignment script, the file structure will be:

```
Group_path/
├── frame_1/
│   ├── R1/
│   │   ├── 1.png
│   │   ├── 2.png
│   │   └── ...
│   ├── R2/
│   ├── R3/
│   ├── ...
│   └── channels/
│       ├── R1ch0.png
│       ├── R1ch1.png
│       └── ...
├── frame_2/
├── frame_3/
└── ...
```

## Installation

1. Clone this repository
2. Install the required dependencies:
   ```
   pip install ultralytics roboflow opencv-python numpy torch segment-anything tqdm
   ```
3. Download the SAM checkpoint file and place it in the `weights` folder:
   ```
   wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P weights/
   ```

## Usage

1. Ensure your data is organized according to the initial file structure mentioned above.
2. Run the image alignment script (`1_Image_alignment.py`) to prepare the data for the pipeline.
3. Update the `Group_path` and `Result_path` variables in `main.py` to point to your aligned input and output directories.
4. Run the main script:
   ```
   python main.py
   ```

## Scripts

1. `0_Yolo_Traning.py`: Script for training the YOLO model on cell detection.
2. `1_Image_alignment.py`: Aligns images from different rounds to ensure proper overlap.
3. `2_Yolo_Prediction.py`: Uses the trained YOLO model to predict bounding boxes for cells.
4. `3_SAM_Prediction.py`: Applies the SAM model for precise cell segmentation and intensity measurement.
5. `main.py`: The main script that orchestrates the entire pipeline.

## Pipeline Flow

The 4I Pipeline consists of several interconnected scripts, each performing a specific function in the data processing and analysis workflow. Here's a detailed explanation of each script and how they work together:

1. **YOLO Training (`0_Yolo_Traning.py`)**
   - Function: Trains the YOLO model for cell detection.
   - Input: Annotated cell images from the Roboflow dataset.
   - Output: Trained YOLO model weights.
   - Connection: The trained model is used by `2_Yolo_Prediction.py` for cell detection.

2. **Image Alignment (`1_Image_alignment.py`)**
   - Function: Aligns and stitches images from different imaging rounds.
   - Input: Raw images from each round and ImageJ alignment files.
   - Output: Aligned and stitched images in the `Group_path` directory.
   - Connection: Prepares the data for processing by subsequent scripts.

3. **YOLO Prediction (`2_Yolo_Prediction.py`)**
   - Function: Detects cells and generates bounding boxes.
   - Input: Aligned images from `Group_path`.
   - Output: Bounding box coordinates for detected cells.
   - Connection: Provides input for the SAM model in `3_SAM_Prediction.py`.

4. **SAM Prediction (`3_SAM_Prediction.py`)**
   - Function: Performs precise cell segmentation and intensity measurement.
   - Input: Aligned images and YOLO-generated bounding boxes.
   - Output: Cell intensity measurements and contours.
   - Connection: Generates the final output data for analysis.

5. **Main Script (`main.py`)**
   - Function: Orchestrates the entire pipeline.
   - Input: Aligned images in `Group_path`.
   - Output: Calls functions from other scripts to process all frames and generate final results.
   - Connection: Ties all the scripts together and manages the overall workflow.

### Data Flow:

1. Raw images → Image Alignment → Aligned images
2. Aligned images → YOLO Prediction → Bounding boxes
3. Aligned images + Bounding boxes → SAM Prediction → Intensity measurements and contours

The main script (`main.py`) coordinates this flow, ensuring that each step is executed in the correct order and with the proper inputs.

## Output

The pipeline generates the following outputs in the specified `Result_path`:

1. YOLO prediction images: `f{frame}R{round}_yolo.png`
2. Intensity measurements: `f{frame}_intensity.csv`
3. Cell contours (if enabled): `f{frame}_countour.csv`

The intensity CSV files contain the following information for each cell:
- Cell center coordinates (x, y)
- Intensity measurements for each channel and round

## Note

This pipeline requires that images are pre-aligned using ImageJ. The `1_Image_alignment.py` script uses the ImageJ alignment results to prepare the data for the subsequent steps in the pipeline. Ensure that your input images are properly aligned before running the main pipeline.
